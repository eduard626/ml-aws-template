# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A boilerplate template to accelerate moving ML projects from POC to production. Provides the scaffolding (Lightning + DVC + Poetry + AWS) so researchers and engineers can focus on model and data work rather than infrastructure. Used as a git submodule (`.ml-aws-template/`) and bootstrapped once to generate a full project structure with training pipelines, data versioning, model release, Docker, and CI/CD.

## Key Commands

```bash
# Bootstrap a new project (one-time, run from the target project root)
python3 .ml-aws-template/bootstrap.py

# Install dependencies
poetry install

# Run training
poetry run python -m {module_name}.train

# Run evaluation
poetry run python -m {module_name}.eval

# Run full DVC pipeline (preprocess → train → evaluate)
dvc repro

# Run individual DVC stages
dvc repro -s preprocess
dvc repro -s train
dvc repro -s evaluate

# Run tests
poetry run pytest

# Lint / format check
poetry run ruff check .

# Release pipeline
dvc repro -f dvc-release.yaml
poetry run python -m {module_name}.scripts.release export-onnx
poetry run python -m {module_name}.scripts.release create-tag
poetry run python -m {module_name}.scripts.release upload-s3

# Model versioning
poetry run python -m {module_name}.scripts.register_model --tag <tag>

# TensorBoard
tensorboard --logdir logs
```

## Architecture

### Pipeline Flow

```
data/raw/ → preprocess → data/processed/ (Parquet)
                              ↓
                           train → models/model.ckpt + TensorBoard logs/
                              ↓
                          evaluate → evaluation_results.json
                              ↓ (optional)
                          release → ONNX export → git tag → S3 upload
```

### Source Structure (`src/`)

- **`config.py`** — Loads `params.yaml`, provides dot-notation access to config sections (data, training, evaluation, release). Computes derived values like input dimension from image_size and channels.
- **`utils.py`** — Factory functions: `setup_logger()`, `create_datamodule()`, `create_model()`, `create_trainer()`. These are the shared setup used by both `train.py` and `eval.py`.
- **`train.py`** — Entry point for training. Creates datamodule/model/trainer via utils, saves checkpoint to `models/model.ckpt`.
- **`eval.py`** — Entry point for evaluation. Loads checkpoint, runs test set, saves metrics JSON.
- **`model/model.py`** — `SimpleClassifier` (Lightning Module): 2-layer neural net with `save_hyperparameters()`.
- **`data/datamodule.py`** — `MyDataModule` (Lightning DataModule): loads Parquet from `data/processed/`, handles train/val/test splits.
- **`data/preprocess.py`** — Data preprocessing stub (raw → processed).
- **`scripts/release.py`** — 3-stage release: ONNX export, git tag creation, S3 upload to `s3://bucket/models/{project}/{version}/`.
- **`scripts/register_model.py`** — Git-based model versioning with annotated tags (`model-{tag}-{commit_hash}`).
- **`scripts/export_and_benchmark.py`** — ONNX export and PyTorch vs ONNX inference benchmarking.

### Template/Infra Files

- **`bootstrap.py`** — One-time project setup: pure Python templating that generates `pyproject.toml`, copies config and source templates with placeholder replacement, creates test files, and sets file permissions. No Node.js or external tools required.
- **`template_configs/`** — Templates for DVC config, Dockerfile (CUDA 12.8 multi-stage build), CircleCI config, `.env.example`, and test files.

### Configuration

- **`params.yaml`** — All hyperparameters: image_size, num_classes, batch_size, lr, max_epochs, num_workers, release S3 settings.
- **`.env`** — Environment variables: `DVC_S3_BUCKET_NAME`, `MODEL_RELEASE_S3_BUCKET`, `MODEL_RELEASE_S3_PREFIX`.

## Tech Stack

- **ML Framework**: Lightning (^2.5.0) + PyTorch (2.7.1, CUDA 12.8 wheels)
- **Data/Model Versioning**: DVC with S3 remote
- **Package Manager**: Poetry (Python >=3.10)
- **Experiment Tracking**: TensorBoard (logs in `logs/`)
- **Model Export**: ONNX + onnxruntime-gpu
- **Linting**: ruff (configured in generated `pyproject.toml`)
- **Testing**: pytest (dev dependency, smoke tests generated by bootstrap)
- **CI/CD**: CircleCI (test → train → Docker build → AWS Batch deploy)
- **Infrastructure**: AWS (S3, ECR, Batch)

## Important Patterns

- All model/data creation goes through `utils.py` factory functions — don't instantiate directly in training/eval scripts.
- Config is centralized in `params.yaml` and accessed via `config.py` — avoid hardcoding hyperparameters.
- DVC tracks pipeline stages and data dependencies — use `dvc repro` rather than running scripts manually.
- PyTorch is pinned to version 2.7.1 from the CUDA 12.8 wheel source (`https://download.pytorch.org/whl/cu128`), configured as an explicit priority source in `pyproject.toml`.
- The Dockerfile uses a multi-stage build with CUDA 12.8 base and runs `dvc repro` as its entrypoint.
- Model versioning is git-based: tags follow the `model-{tag}-{commit_hash}` pattern.
